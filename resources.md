Since this is my first Kaggle Competition along side kernels I will read a lot about how to actually compete in a Kaggle competition.
Here are the resources I found and I am reading

- 1 [How to rank 10% in your first Kaggle Competition](http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/)

- 2 [Beating Kaggle the Easy way](http://www.ke.tu-darmstadt.de/lehre/arbeiten/studien/2015/Dong_Ying.pdf)

- 3 [Previous competition winner interview on github](https://github.com/ChenglongChen/Kaggle_CrowdFlower/blob/master/BlogPost/BlogPost.md)

Since after couple of days of reading the material looked to confused, I decided to enroll in Coursera [How to win a Data Science Competition - Learn from top kagglers](https://www.coursera.org/learn/competitive-data-science), I will see how to organize the material.

Machine Learning Models:
- 1 [Random Forest](https://www.datasciencecentral.com/profiles/blogs/random-forests-explained-intuitively)
- 2 [Gradient Boosting](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)
- 3 [KNN](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/)

Feature preprocessing
- [Preprocessing in Sklearn](https://scikit-learn.org/stable/modules/preprocessing.html)
- [Andrew NG about gradient descent and feature scaling](https://www.coursera.org/learn/machine-learning/lecture/xx3Da/gradient-descent-in-practice-i-feature-scaling)
- [Feature Scaling and the effect of standardization for machine learning algorithms](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html)

Feature generation
- [Discover Feature Engineering, How to Engineer Features and How to Get Good at It](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)
- [Discussion of feature engineering on Quora](https://www.quora.com/What-are-some-best-practices-in-Feature-Engineering)

Text processsing
- [Introduction to Word Embedding Models with Word2Vec](https://taylorwhitten.github.io/blog/word2vec)
- [Word2Vec Tutorial](https://rare-technologies.com/word2vec-tutorial/)
- [Fine-Tuning deep learning models](https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html)
- [Using pre-trained models](https://keras.io/applications/)

Validation
- [Avoid LB shuffle](http://www.chioka.in/how-to-select-your-final-models-in-a-kaggle-competitio/)
- [SKlearn validation page](https://scikit-learn.org/stable/modules/cross_validation.html)

Hyperparam Tuning
- [Hyperopt][http://fastml.com/optimizing-hyperparams-with-hyperopt/]

Past solutions
- http://ndres.me/kaggle-past-solutions/
- https://www.kaggle.com/wiki/PastSolutions
- http://www.chioka.in/kaggle-competition-solutions/
- https://github.com/ShuaiW/kaggle-classification/
