{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\tVALIDATION + metric LGB baseline\t0.692898\t0.517036\t0.62900\tUses early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from kaggle.competitions import twosigmanews\n",
    "# You can only call make_env() once, so don't lose it!\n",
    "env = twosigmanews.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c20fa6deeac9d374c98774abd90bdc76b023ee63"
   },
   "outputs": [],
   "source": [
    "(market_train_df, news_train_df) = env.get_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ef1af5a9fc2bdc1ebde967994b9bb68f4745353"
   },
   "source": [
    "<h1>Basic data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddaf2b1ae8836ff0d9e3474a2f974d5f4c70b570"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04fe6a44a65a7b66fa128f24acf6717eda1f6e20"
   },
   "outputs": [],
   "source": [
    "market_train_df['close_to_open'] =  np.abs(market_train_df['close'] / market_train_df['open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "19ef8496d92912fd56dce27ea0548c8a42c92212",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "market_train_df['assetName_mean_open'] = market_train_df.groupby('assetName')['open'].transform('mean')\n",
    "market_train_df['assetName_mean_close'] = market_train_df.groupby('assetName')['close'].transform('mean')\n",
    "\n",
    "# if open price is too far from mean open price for this company, replace it. Otherwise replace close price.\n",
    "for i, row in market_train_df.loc[market_train_df['close_to_open'] >= 2].iterrows():\n",
    "    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n",
    "        market_train_df.iloc[i,5] = row['assetName_mean_open']\n",
    "    else:\n",
    "        market_train_df.iloc[i,4] = row['assetName_mean_close']\n",
    "        \n",
    "for i, row in market_train_df.loc[market_train_df['close_to_open'] <= 0.5].iterrows():\n",
    "    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n",
    "        market_train_df.iloc[i,5] = row['assetName_mean_open']\n",
    "    else:\n",
    "        market_train_df.iloc[i,4] = row['assetName_mean_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ba2dd94ee767d1e34c3380a8646bb3cf9fba3d4"
   },
   "outputs": [],
   "source": [
    "market_train_df = market_train_df.loc[market_train_df['time'] >= '2010-01-01 22:00:00+0000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "84b5a58f67ebded82e6aabc66ca36411e6db35a9"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "bottom, top = market_train_df.returnsOpenNextMktres10.quantile(0.001), market_train_df.returnsOpenNextMktres10.quantile(0.999)\n",
    "returns, binwidth = market_train_df.returnsOpenNextMktres10.clip(bottom, top), 0.005\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.hist(returns,  bins=np.arange(min(returns), max(returns) + binwidth, binwidth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1887a485db1d991ced5e9c81b019efd640373636"
   },
   "outputs": [],
   "source": [
    "market_train_df.returnsOpenNextMktres10 = market_train_df.returnsOpenNextMktres10.clip(bottom, top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e835ea6c27cd45494d6a52d8c37481297419351"
   },
   "source": [
    "<h1>Test-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8a70fc5ed68b41a149f72667da7d0cf8a25e5809"
   },
   "outputs": [],
   "source": [
    "X, Y = market_train_df.iloc[:, (market_train_df.columns != 'assetCode') & (market_train_df.columns != 'assetName') &(market_train_df.columns != 'time') & (market_train_df.columns != 'returnsOpenNextMktres10')], market_train_df['returnsOpenNextMktres10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b947762ed96023f9ca033ed2a1097a07677513d1"
   },
   "outputs": [],
   "source": [
    "split = int(len(X) * 0.8)\n",
    "test_train_distsance = 20000\n",
    "X_train, X_val = X[:split - test_train_distsance], X[split:]\n",
    "Y_train, Y_val = Y[:split - test_train_distsance], Y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ecc3124e7d6ef82c2a5e10f07bf415d6024c19d4"
   },
   "outputs": [],
   "source": [
    "print(len(X_val), len(Y_val))\n",
    "universe_filter = market_train_df['universe'][split:] == 1.0\n",
    "X_val = X_val[universe_filter]\n",
    "Y_val = Y_val[universe_filter]\n",
    "print(len(X_val), len(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b60b7e9bb1f29e6ce88d2286aa889dfe1c00a3ab"
   },
   "outputs": [],
   "source": [
    "# this is a time_val series used to calc the sigma_score later, applied split and universe filter\n",
    "time_val = market_train_df['time'][split:][universe_filter]\n",
    "assert len(time_val) == len(X_val)\n",
    "time_train = market_train_df['time'][:split - test_train_distsance]\n",
    "assert len(time_train) == len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c777480aeb27f85862e6e74ddccd52163a6a988c"
   },
   "source": [
    "<h1>Metric Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4be9bbbd9f8f656dfb627564167276c331fe08cf"
   },
   "outputs": [],
   "source": [
    "def sigma_score(preds, valid_data):\n",
    "    df_time = valid_data.params['extra_time'] # will be injected afterwards\n",
    "    labels = valid_data.get_label()\n",
    "    \n",
    "#    assert len(labels) == len(df_time)\n",
    "\n",
    "    x_t = preds * labels #  * df_valid['universe'] -> Here we take out the 'universe' term because we already keep only those equals to 1.\n",
    "    \n",
    "    # Here we take advantage of the fact that `labels` (used to calculate `x_t`)\n",
    "    # is a pd.Series and call `group_by`\n",
    "    x_t_sum = x_t.groupby(df_time).sum()\n",
    "    score = x_t_sum.mean() / x_t_sum.std()\n",
    "\n",
    "    return 'sigma_score', score, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b26a9fad87a29174ad23bc7290e51da6ab68f51"
   },
   "source": [
    "<h1>Fit basic LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a420ee62c404625c9ce41f8eb048d2cafcedac0"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a344616aa9b08f8fc5fafb48573c8954fcbb65d"
   },
   "outputs": [],
   "source": [
    "train_cols = X.columns.tolist()\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train.values, Y_train, feature_name=train_cols, free_raw_data=False)\n",
    "lgb_val = lgb.Dataset(X_val.values, Y_val, feature_name=train_cols, free_raw_data=False)\n",
    "\n",
    "lgb_train.params = {\n",
    "    'extra_time' : time_train.factorize()[0]\n",
    "}\n",
    "lgb_val.params = {\n",
    "    'extra_time' : time_val.factorize()[0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38a84acbf9adc645bbe4d3dbb9c240f5a29e1690"
   },
   "outputs": [],
   "source": [
    "lgb_params = dict(\n",
    "    objective = 'regression_l1',\n",
    "    learning_rate = 0.1,\n",
    "    num_leaves = 127,\n",
    "    max_depth = -1,\n",
    "#     min_data_in_leaf = 1000,\n",
    "#     min_sum_hessian_in_leaf = 10,\n",
    "    bagging_fraction = 0.75,\n",
    "    bagging_freq = 2,\n",
    "    feature_fraction = 0.5,\n",
    "    lambda_l1 = 0.0,\n",
    "    lambda_l2 = 1.0,\n",
    "    metric = 'None', # This will ignore the loss objetive and use sigma_score instead,\n",
    "    seed = 42 # Change for better luck! :)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90df77baaa079c7c2083dd0855881c579173af9f"
   },
   "outputs": [],
   "source": [
    "training_results = {}\n",
    "model = lgb.train(lgb_params, lgb_train, num_boost_round=1000, valid_sets=(lgb_val,lgb_train), valid_names=('valid','train'), verbose_eval=25,\n",
    "              early_stopping_rounds=100, feval=sigma_score, evals_result=training_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b6420cf4302cd39f499d14d6e0c780d63cf672b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(training_results['valid']['sigma_score'])\n",
    "plt.plot(training_results['train']['sigma_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7aa23a84c5ccf7b3a5b4f9a610abbfd8d2843ce"
   },
   "outputs": [],
   "source": [
    "features = market_train_df.columns[(market_train_df.columns != 'assetCode') & (market_train_df.columns != 'assetName') &(market_train_df.columns != 'time') & (market_train_df.columns != 'returnsOpenNextMktres10')]\n",
    "print(features[0], features[1], features[13], features[7], features[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ed86abeb180f3b008189ed98427f1850cb3d8a2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=lgb.plot_importance(model)\n",
    "x.figure.set_size_inches(10, 30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "724c38149860c8e9058474ac9045c2301e8a20da"
   },
   "outputs": [],
   "source": [
    "# You can only iterate through a result from `get_prediction_days()` once\n",
    "# so be careful not to lose it once you start iterating.\n",
    "days = env.get_prediction_days()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8056b881707072c379ad2e89b9c59c3c041a2ab7"
   },
   "source": [
    "## Main Loop\n",
    "Let's loop through all the days and make our random predictions.  The `days` generator (returned from `get_prediction_days`) will simply stop returning values once you've reached the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf23c5fff4e62bf66e61fc743fa96b01e975100c"
   },
   "outputs": [],
   "source": [
    "def prepare_predictions(market_obs_df):\n",
    "    market_obs_df['close_to_open'] =  np.abs(market_obs_df['close'] / market_obs_df['open'])\n",
    "    market_obs_df['universe'] =  1\n",
    "    market_obs_df['assetName_mean_open'] = market_obs_df.groupby('assetName')['open'].transform('mean')\n",
    "    market_obs_df['assetName_mean_close'] = market_obs_df.groupby('assetName')['close'].transform('mean')\n",
    "\n",
    "    # if open price is too far from mean open price for this company, replace it. Otherwise replace close price.\n",
    "    for i, row in market_obs_df.loc[market_obs_df['close_to_open'] >= 2].iterrows():\n",
    "        if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n",
    "            market_obs_df.iloc[i,5] = row['assetName_mean_open']\n",
    "        else:\n",
    "            market_obs_df.iloc[i,4] = row['assetName_mean_close']\n",
    "\n",
    "    for i, row in market_obs_df.loc[market_obs_df['close_to_open'] <= 0.5].iterrows():\n",
    "        if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n",
    "            market_obs_df.iloc[i,5] = row['assetName_mean_open']\n",
    "        else:\n",
    "            market_obs_df.iloc[i,4] = row['assetName_mean_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef60bc52a8a228e5a2ce18e4bd416f1f1f25aeae"
   },
   "outputs": [],
   "source": [
    "for (market_obs_df, news_obs_df, predictions_template_df) in days:\n",
    "    prepare_predictions(market_obs_df)\n",
    "    predictions = market_obs_df.iloc[:, (market_obs_df.columns != 'assetCode') & (market_obs_df.columns != 'assetName') &(market_obs_df.columns != 'time') ].values\n",
    "    predictions_template_df.confidenceValue = model.predict(predictions).clip(-1, 1)\n",
    "    env.predict(predictions_template_df)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c8fbcca87c7f6abc53e86408417bf12ce21bb7f"
   },
   "source": [
    "## **`write_submission_file`** function\n",
    "\n",
    "Writes your predictions to a CSV file (`submission.csv`) in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c8ed34ffb2c47c6e124530ec798c0b4eb01ddd5"
   },
   "outputs": [],
   "source": [
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d38aa8a67cad3f0c105db7e764ec9b805db39ceb"
   },
   "outputs": [],
   "source": [
    "# We've got a submission file!\n",
    "import os\n",
    "print([filename for filename in os.listdir('.') if '.csv' in filename])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f464f37885ffa763a2592e2867d74685f75be506"
   },
   "source": [
    "As indicated by the helper message, calling `write_submission_file` on its own does **not** make a submission to the competition.  It merely tells the module to write the `submission.csv` file as part of the Kernel's output.  To make a submission to the competition, you'll have to **Commit** your Kernel and find the generated `submission.csv` file in that Kernel Version's Output tab (note this is _outside_ of the Kernel Editor), then click \"Submit to Competition\".  When we re-run your Kernel during Stage Two, we will run the Kernel Version (generated when you hit \"Commit\") linked to your chosen Submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e3a267ea3149403c49ff59515a1a669ca2d1f9f"
   },
   "source": [
    "## Restart the Kernel to run your code again\n",
    "In order to combat cheating, you are only allowed to call `make_env` or iterate through `get_prediction_days` once per Kernel run.  However, while you're iterating on your model it's reasonable to try something out, change the model a bit, and try it again.  Unfortunately, if you try to simply re-run the code, or even refresh the browser page, you'll still be running on the same Kernel execution session you had been running before, and the `twosigmanews` module will still throw errors.  To get around this, you need to explicitly restart your Kernel execution session, which you can do by pressing the Restart button in the Kernel Editor's bottom Console tab:\n",
    "![Restart button](https://i.imgur.com/hudu8jF.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
