{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores 0.704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fadffcaa4012badddbe0acd50c7b57b0f65843f2"
   },
   "source": [
    "<h1>Single model submission template.\n",
    "\n",
    "<p>every model to be used must satisfy the APIs requirements of model_template.py, and must pass all the tests like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2afca6b204da170ff55f3037a9f1bfda05c0a7c4"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a template for the APIs of models to be used into the stacking framework.\n",
    "run with Python 3.x\n",
    "\"\"\"\n",
    "from time import time, ctime\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "from matplotlib import pyplot as plt\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "from datetime import datetime, date\n",
    "import shap\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "83cc460d930508a9445170726057d4ef07c254c9"
   },
   "source": [
    "<h1>Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from kaggle.competitions import twosigmanews\n",
    "# You can only call make_env() once, so don't lose it!\n",
    "env = twosigmanews.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c20fa6deeac9d374c98774abd90bdc76b023ee63"
   },
   "outputs": [],
   "source": [
    "(market_train_df, news_train_df) = env.get_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "411b70914babbfa97b11a7d72409d92de936d721"
   },
   "source": [
    "<h1>`Datacleaning and preprocessing procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ea1d2106702907555a9794d4194b4a23915b5ead"
   },
   "source": [
    "datacleaning will applied to the whole dataset for every model, the only requirements is that at the end of the procedure ***NO NEW FEATURES can be added here***. They must be added inside the feature generation section of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc6b6b18ea855a1ac6a7b406a2053cd10ebc3493"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2531071b01eae4a4451eb5c9a8a494adebdeaa05"
   },
   "outputs": [],
   "source": [
    "market_train_df = market_train_df.loc[market_train_df['time'] >= '2010-01-01 22:00:00+0000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c921f8243bbcb70223cb5d931d19a2c6191e5a5"
   },
   "source": [
    "<h1>Initialize and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b552b6f1fbac2a1e78fdafd0612c08ce8684357b"
   },
   "outputs": [],
   "source": [
    "model = model('lgbm_71_leak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "165a4b006519272bd71db59e430782e6e48eaabd"
   },
   "outputs": [],
   "source": [
    "target = market_train_df.returnsOpenNextMktres10\n",
    "market_train_df.drop('returnsOpenNextMktres10', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0277beff74324c769a7ea4d7ce59553873204f86"
   },
   "outputs": [],
   "source": [
    "model.train([market_train_df, news_train_df], target, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ef8574c1c8fd00d1ea74680cf34b67a35f0b70d"
   },
   "outputs": [],
   "source": [
    "max_values, min_values, max_lag = model.maxs, model.mins, model.max_lag # values used for normalization during predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c102bb7bdc0a399341d588039a62449d01b76391"
   },
   "outputs": [],
   "source": [
    "model.inspect(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33a05f3a4f3d6e20ca59fc49e4c2c3b3029254bd"
   },
   "source": [
    "<h1>Prediction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddd50a7872c8c40d66429c2ff988bb3b827f7e3f"
   },
   "outputs": [],
   "source": [
    "days = env.get_prediction_days()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef60bc52a8a228e5a2ce18e4bd416f1f1f25aeae"
   },
   "outputs": [],
   "source": [
    "\"\"\"locals required\n",
    "model: instance of model class defined above\n",
    "max_values, min_values: (pd.DataFrame)\n",
    "max_lag: (int)\n",
    "\"\"\"\n",
    "from time import time\n",
    "n_days, prep_time, prediction_time, packaging_time = 0, 0, 0, 0\n",
    "total_market_obs_df = []\n",
    "for (market_obs_df, news_obs_df, predictions_template_df) in days:\n",
    "    n_days +=1\n",
    "    if (n_days%50==0): print(n_days,end=' ')\n",
    "    t = time()\n",
    "    market_obs_df['time'] = market_obs_df['time'].dt.date\n",
    "\n",
    "    total_market_obs_df.append(market_obs_df)\n",
    "    if len(total_market_obs_df) == 1:\n",
    "        history_df = total_market_obs_df[0]\n",
    "    else:\n",
    "        history_df = pd.concat(total_market_obs_df[-(max_lag + 1):])\n",
    "        \n",
    "    confidence = model.predict_rolling([history_df, None], market_obs_df, verbose=True, normalize=True, normalize_vals = [max_values, min_values])      \n",
    "        \n",
    "    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n",
    "    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n",
    "    env.predict(predictions_template_df)\n",
    "    packaging_time += time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e996e8d31a1d28fced248f48c1874df2568cd29b"
   },
   "outputs": [],
   "source": [
    "history_market_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c8fbcca87c7f6abc53e86408417bf12ce21bb7f"
   },
   "source": [
    "## **`write_submission_file`** function\n",
    "\n",
    "Writes your predictions to a CSV file (`submission.csv`) in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c8ed34ffb2c47c6e124530ec798c0b4eb01ddd5"
   },
   "outputs": [],
   "source": [
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d38aa8a67cad3f0c105db7e764ec9b805db39ceb"
   },
   "outputs": [],
   "source": [
    "# We've got a submission file!\n",
    "import os\n",
    "print([filename for filename in os.listdir('.') if '.csv' in filename])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f464f37885ffa763a2592e2867d74685f75be506"
   },
   "source": [
    "As indicated by the helper message, calling `write_submission_file` on its own does **not** make a submission to the competition.  It merely tells the module to write the `submission.csv` file as part of the Kernel's output.  To make a submission to the competition, you'll have to **Commit** your Kernel and find the generated `submission.csv` file in that Kernel Version's Output tab (note this is _outside_ of the Kernel Editor), then click \"Submit to Competition\".  When we re-run your Kernel during Stage Two, we will run the Kernel Version (generated when you hit \"Commit\") linked to your chosen Submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e3a267ea3149403c49ff59515a1a669ca2d1f9f"
   },
   "source": [
    "## Restart the Kernel to run your code again\n",
    "In order to combat cheating, you are only allowed to call `make_env` or iterate through `get_prediction_days` once per Kernel run.  However, while you're iterating on your model it's reasonable to try something out, change the model a bit, and try it again.  Unfortunately, if you try to simply re-run the code, or even refresh the browser page, you'll still be running on the same Kernel execution session you had been running before, and the `twosigmanews` module will still throw errors.  To get around this, you need to explicitly restart your Kernel execution session, which you can do by pressing the Restart button in the Kernel Editor's bottom Console tab:\n",
    "![Restart button](https://i.imgur.com/hudu8jF.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
